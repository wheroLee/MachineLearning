{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('py38_tf23': conda)"
  },
  "interpreter": {
   "hash": "12258280f3a01847609cecdf288ec4ca09bb9de7961a66e3094524ad48475df7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# RandomGridSearch for Neural Network Machine Learning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "grid_NN = {'n_estimators': n_estimators,\r\n",
    "               'max_features': max_features,\r\n",
    "               'max_depth': max_depth,\r\n",
    "               'min_samples_split': min_samples_split,\r\n",
    "               'min_samples_leaf': min_samples_leaf,\r\n",
    "               'bootstrap': bootstrap}"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'n_estimators' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8c1976180fe3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m grid_NN = {'n_estimators': n_estimators,\n\u001b[0m\u001b[0;32m      2\u001b[0m                \u001b[1;34m'max_features'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                \u001b[1;34m'max_depth'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                \u001b[1;34m'min_samples_split'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                \u001b[1;34m'min_samples_leaf'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n_estimators' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = None\r\n",
    "def build_model(iunit, ounit, train_dataset,activation=\"sigmoid\",loss='binary_crossentropy',metrics=['accuracy']):\r\n",
    "    model = keras.Sequential([\r\n",
    "      layers.Dense(iunit, activation='relu', \r\n",
    "                   kernel_regularizer=keras.regularizers.l2(0.01), \r\n",
    "                   input_shape=[len(train_dataset.keys())]),\r\n",
    "      layers.Dense(iunit, activation='relu', \r\n",
    "                   kernel_regularizer=keras.regularizers.l2(0.001)\r\n",
    "                   ), \r\n",
    "      # layers.Dense(iunit, activation='relu', \r\n",
    "      #              kernel_regularizer=keras.regularizers.l2(0.001)\r\n",
    "      #              ),                     \r\n",
    "      # layers.Dense(iunit, activation='relu', \r\n",
    "      #              kernel_regularizer=keras.regularizers.l2(0.001)\r\n",
    "      #              ),                    \r\n",
    "      layers.Dense(ounit,activation=activation)\r\n",
    "      ])\r\n",
    "    # optimizer = tf.keras.optimizers.RMSprop(lr=0.01, rho=0.9, epsilon=None, decay=0.0)\r\n",
    "    #optimizer = tf.keras.optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\r\n",
    "    #optimizer = tf.keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\r\n",
    "    #optimizer = tf.keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\r\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\r\n",
    "    # optimizer = tf.keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\r\n",
    "    #optimizer = tf.keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\r\n",
    "    \r\n",
    "    model.compile(\r\n",
    "      loss=loss, #'mse', #'binary_crossentropy'\r\n",
    "      optimizer=optimizer,\r\n",
    "      # 'mae', 'mse', 'mape','accuracy'\r\n",
    "      metrics=metrics)\r\n",
    "\r\n",
    "    return model  "
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}